{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cfb6b172",
      "metadata": {
        "id": "cfb6b172"
      },
      "source": [
        "# Worksheet 8: Decision Tree, Ensemble Methods & Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acedebe5",
      "metadata": {
        "id": "acedebe5"
      },
      "source": [
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9ea8bd28",
      "metadata": {
        "id": "9ea8bd28"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b107b1",
      "metadata": {
        "id": "c1b107b1"
      },
      "source": [
        "## 2. Custom Decision Tree (Using Information Gain)\n",
        "This is a **simple implementation** of a Decision Tree using entropy and information gain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4d857845",
      "metadata": {
        "id": "4d857845"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        probs = np.bincount(y) / len(y)\n",
        "        return -np.sum(probs * np.log2(probs + 1e-9))\n",
        "\n",
        "    def _information_gain(self, parent, left, right):\n",
        "        weight_l = len(left) / len(parent)\n",
        "        weight_r = len(right) / len(parent)\n",
        "        return self._entropy(parent) - (weight_l * self._entropy(left) + weight_r * self._entropy(right))\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if len(np.unique(y)) == 1 or (self.max_depth and depth >= self.max_depth):\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        best_gain = -1\n",
        "        best_split = None\n",
        "\n",
        "        for feature in range(X.shape[1]):\n",
        "            for threshold in np.unique(X[:, feature]):\n",
        "                left = y[X[:, feature] <= threshold]\n",
        "                right = y[X[:, feature] > threshold]\n",
        "                if len(left) == 0 or len(right) == 0:\n",
        "                    continue\n",
        "                gain = self._information_gain(y, left, right)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split = (feature, threshold)\n",
        "\n",
        "        if best_split is None:\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        feature, threshold = best_split\n",
        "        left_mask = X[:, feature] <= threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        return {\n",
        "            'feature': feature,\n",
        "            'threshold': threshold,\n",
        "            'left': self._build_tree(X[left_mask], y[left_mask], depth+1),\n",
        "            'right': self._build_tree(X[right_mask], y[right_mask], depth+1)\n",
        "        }\n",
        "\n",
        "    def _predict_one(self, x, tree):\n",
        "        if 'class' in tree:\n",
        "            return tree['class']\n",
        "        if x[tree['feature']] <= tree['threshold']:\n",
        "            return self._predict_one(x, tree['left'])\n",
        "        return self._predict_one(x, tree['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_one(x, self.tree) for x in X]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f20348",
      "metadata": {
        "id": "19f20348"
      },
      "source": [
        "## 3. Load and Split Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "075daafa",
      "metadata": {
        "id": "075daafa"
      },
      "outputs": [],
      "source": [
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f81500",
      "metadata": {
        "id": "56f81500"
      },
      "source": [
        "## 4. Train and Evaluate Custom Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0e7711ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e7711ad",
        "outputId": "510dc8d8-8636-4115-d932-1bbc184b500b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Decision Tree Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "print(\"Custom Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_custom))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d87b54",
      "metadata": {
        "id": "50d87b54"
      },
      "source": [
        "## 5. Train and Evaluate Scikit-learn Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "abfd2623",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abfd2623",
        "outputId": "99b33c7f-8238-4d25-954e-3a2d3726db99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Decision Tree Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sk_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sk_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sk = sk_tree.predict(X_test)\n",
        "print(\"Scikit-learn Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_sk))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8300ff6e",
      "metadata": {
        "id": "8300ff6e"
      },
      "source": [
        "## 6. Ensemble Methods – Wine Dataset (Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "004891df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "004891df",
        "outputId": "e997ee7e-6521-4276-9033-93d19508f822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 Score: 0.9439974457215836\n",
            "Random Forest F1 Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "dt_f1 = f1_score(y_test, dt.predict(X_test), average='weighted')\n",
        "rf_f1 = f1_score(y_test, rf.predict(X_test), average='weighted')\n",
        "\n",
        "print(\"Decision Tree F1 Score:\", dt_f1)\n",
        "print(\"Random Forest F1 Score:\", rf_f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0070d13c",
      "metadata": {
        "id": "0070d13c"
      },
      "source": [
        "## 7. Hyperparameter Tuning – Random Forest (GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "154f061d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "154f061d",
        "outputId": "daba2954-5017-4af7-92f7-628cd77fb368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best F1 Score: 0.9782952128219708\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42),\n",
        "                    param_grid,\n",
        "                    scoring='f1_weighted',\n",
        "                    cv=5)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best F1 Score:\", grid.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9dfdf80",
      "metadata": {
        "id": "c9dfdf80"
      },
      "source": [
        "## 8. Regression – Decision Tree & Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "988bdc16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "988bdc16",
        "outputId": "9aba5862-5a4a-421d-d35f-ef3ea1202146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT MSE: 0.16666666666666666\n",
            "RF MSE: 0.06483333333333333\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X, y = wine.data, wine.target.astype(float)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "dt_reg.fit(X_train, y_train)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "print(\"DT MSE:\", mean_squared_error(y_test, dt_reg.predict(X_test)))\n",
        "print(\"RF MSE:\", mean_squared_error(y_test, rf_reg.predict(X_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20efad3a",
      "metadata": {
        "id": "20efad3a"
      },
      "source": [
        "## 9. Hyperparameter Tuning – Random Forest Regressor (RandomizedSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f8974b26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8974b26",
        "outputId": "180f1603-6ce7-4fe3-ff9c-9999b8339979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': None}\n",
            "Best Score: 0.9210582730275565\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=5,\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Score:\", random_search.best_score_)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}